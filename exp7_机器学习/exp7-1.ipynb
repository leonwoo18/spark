{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features=[-1.0,1.5,1.3], label=1.0 -> prob=[0.0013759947069214356,0.9986240052930786], prediction=1.0 \n",
      "features=[3.0,2.0,-0.1], label=0.0 -> prob=[0.9816604009374171,0.018339599062582944], prediction=0.0 \n",
      "features=[0.0,2.2,-1.5], label=1.0 -> prob=[0.0016981475578358373,0.9983018524421641], prediction=1.0 \n",
      "\n",
      "\n",
      "features=[-1.0,1.5,1.3], label=1.0 -> prob=[0.05707304171033977,0.9429269582896603], prediction=1.0 \n",
      "features=[3.0,2.0,-0.1], label=0.0 -> prob=[0.9238522311704088,0.07614776882959128], prediction=0.0 \n",
      "features=[0.0,2.2,-1.5], label=1.0 -> prob=[0.10972776114779119,0.8902722388522087], prediction=1.0 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    " \n",
    "# $example on$\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "# $example off$\n",
    "from pyspark.sql import SparkSession\n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"EstimatorTransformerParamExample\")\\\n",
    "        .getOrCreate()\n",
    " \n",
    "    # label 列为标记，features 是特征向量\n",
    "    training = spark.createDataFrame([\n",
    "        (1.0, Vectors.dense([0.0, 1.1, 0.1])),\n",
    "        (0.0, Vectors.dense([2.0, 1.0, -1.0])),\n",
    "        (0.0, Vectors.dense([2.0, 1.3, 1.0])),\n",
    "        (1.0, Vectors.dense([0.0, 1.2, -0.5]))], [\"label\", \"features\"])\n",
    "#-------------------------------------------------------------------------------------------------------------\n",
    "    # 创建一个逻辑回归算法，算法是 Estimator.\n",
    "    # maxIter 最大迭代次数，regParam 是正则化参数\n",
    "    lr = LogisticRegression(maxIter=10, regParam=0.01)                                ################\n",
    "    # Print out the parameters, documentation, and any default values.                #              #\n",
    "    # print(\"LogisticRegression parameters:\\n\" + lr.explainParams() + \"\\n\")           #   model 1    #\n",
    "                                                                                      #              #\n",
    "    # 算法是一个Estimator，学习训练数据以后，会返回一个模型，模型是Transformer        ################\n",
    "    model1 = lr.fit(training)\n",
    " \n",
    "    #下面两行去掉注释，会打印model1的相关参数\n",
    "    #print(\"Model 1 was fit using parameters: \")\n",
    "    #print(model1.extractParamMap())\n",
    "#-------------------------------------------------------------------------------------------------------------\n",
    "    #-----paraMap1-------------------------------\n",
    "    # paramMaps可以调整算法的参数，是字典类型\n",
    "    paramMap = {lr.maxIter: 20}\n",
    "    paramMap[lr.maxIter] = 30  \n",
    "    #调整了算法正则系数regParam，和判断概率阈值\n",
    "    paramMap.update({lr.regParam: 0.1, lr.threshold: 0.55}) \n",
    " \n",
    "    #-----paraMap2--------------------------------\n",
    "    #你可以通过合并字典修改参数。\n",
    "    #可以修改预测列名称\n",
    "    paramMap2 = {lr.probabilityCol: \"probability\"}               ################################\n",
    "                                                                 #                              #\n",
    "    #------结合-----------------------------------               #                              #\n",
    "    paramMapCombined = paramMap.copy()                           #                              #\n",
    "    paramMapCombined.update(paramMap2)                           #           model 2            #\n",
    "                                                                 #                              #\n",
    "                                                                 #                              #\n",
    "    # 把训练数据、combine放进来拟合                              #                              #\n",
    "    model2 = lr.fit(training, paramMapCombined)                  #                              #\n",
    "     #下面两行去掉注释，会打印model2的相关参数                   ###############################\n",
    "    #print(\"Model 2 was fit using parameters: \")\n",
    "    #print(model2.extractParamMap())\n",
    "#------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 测试数据\n",
    "    test = spark.createDataFrame([\n",
    "        (1.0, Vectors.dense([-1.0, 1.5, 1.3])),\n",
    "        (0.0, Vectors.dense([3.0, 2.0, -0.1])),\n",
    "        (1.0, Vectors.dense([0.0, 2.2, -1.5]))], [\"label\", \"features\"])\n",
    " \n",
    "    predictions = (model1.transform(test),model2.transform(test))\n",
    " \n",
    "    \n",
    "    for prediction in predictions:\n",
    "        result = prediction.select(\"features\", \"label\", \"probability\", \"prediction\").collect()\n",
    "        for row in result:\n",
    "            print(\"features=%s, label=%s -> prob=%s, prediction=%s \"\n",
    "              % (row.features, row.label, row.probability, row.prediction))\n",
    "        print(\"\\n\")\n",
    " \n",
    "    spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
